{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detect_object_in_webcam_video.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi6exYZagKnp",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-pdc2-students/blob/master/iti107/session-5/od_using_tfod_api/object_detection_using_tfod_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFSqkTCdWKMI"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from shutil import copy2\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wy72mWwAWKMK"
      },
      "source": [
        "## 2. Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4bU0Gi2gKn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root Tensorflow model directory. Modify this accordingly\n",
        "TF_MODELS_RESEARCH_DIR = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research'\n",
        "TF_SLIM_DIR = os.path.join(TF_MODELS_RESEARCH_DIR, 'slim')\n",
        "TF_OD_DIR = os.path.join(TF_MODELS_RESEARCH_DIR, 'object_detection')\n",
        "\n",
        "sys.path.append(TF_MODELS_RESEARCH_DIR)\n",
        "sys.path.append(TF_SLIM_DIR)\n",
        "sys.path.append(TF_OD_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "### TFOD API imports\n",
        "Here are the imports of the required object detection modules in TFOD API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v7m_NY_aWKMK",
        "colab": {}
      },
      "source": [
        "from utils import ops as utils_ops\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cfn_tRFOWKMO"
      },
      "source": [
        "## 3. Model preparation \n",
        "choose the model to detect, this is for downloading models like SSD, YOLO, Fast RNN etc Skip this step if you have your own model Frozen inference graph and you wish to try that.\n",
        "Skip and Go to next step and give the path where your model (frozen inference graph.pb) is stored\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VyPz_t8WWKMQ",
        "colab": {}
      },
      "source": [
        "# What model to download.\n",
        "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "LABEL_FILE = 'mscoco_label_map.pbtxt'\n",
        "PATH_TO_LABELS = os.path.join(TF_OD_DIR, 'data',LABEL_FILE)\n",
        "\n",
        "copy2(PATH_TO_LABELS, LABEL_FILE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llx5YtmthBBm",
        "colab_type": "text"
      },
      "source": [
        "Give the path to 2 things here\n",
        "1. label map \n",
        "2. frozen inference graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC9lejgVgKoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TO_FROZEN_GRAPH = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research\\\\object_detection\\\\ssd_mobilenet_v1_coco_2018_03_29\\\\frozen_inference_graph_final.pb'\n",
        "PATH_TO_LABELS = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research\\\\object_detection\\\\ssd_mobilenet_v1_coco_2018_03_29\\\\my_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ai8pLZZWKMS"
      },
      "source": [
        "### Download Model\n",
        "\n",
        "This is to download frozen inference graph for model zoo, skip this as well if you have a custom one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KILYnwR5WKMS",
        "colab": {}
      },
      "source": [
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "    file_name = os.path.basename(file.name)\n",
        "    if 'frozen_inference_graph.pb' in file_name:\n",
        "        tar_file.extract(file, os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YBcB9QHLWKMU"
      },
      "source": [
        "### Load the (frozen) Tensorflow model into memory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KezjCRVvWKMV",
        "colab": {}
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.compat.v1.GraphDef()\n",
        "    with tf.compat.v1.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "### Loading label map\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDbpHkiWWKMX",
        "colab": {}
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H0_1AGhrWKMc"
      },
      "source": [
        "## 4. Object Detection on Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJWvK4rKgKoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EFsoUHvbWKMZ"
      },
      "source": [
        "### Helper code\n",
        "\n",
        "The image is read using Pillow as an Image object. Image.size gives the dimension of image as widht, height ordering. `Image.getdata()` gives a flattened array of bytes, so we need to reshape it to `(height, width, channels)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aSlYc3JkWKMa",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92BHxzcNWKMf",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(image_path, graph):\n",
        "    image = Image.open(image_path)\n",
        "    \n",
        "    with graph.as_default():\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "        # Get handles to input and output tensors\n",
        "            image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
        "            detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
        "            detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
        "            detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "            image_np = load_image_into_numpy_array(image)\n",
        "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "            # Run inference\n",
        "            \n",
        "            (boxes, scores, classes, num) = sess.run(\n",
        "                            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "                            feed_dict={image_tensor: image_np_expanded})\n",
        "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                        image_np,\n",
        "                        np.squeeze(boxes),\n",
        "                        np.squeeze(classes).astype(np.int32),\n",
        "                        np.squeeze(scores),\n",
        "                        category_index,\n",
        "                        min_score_thresh=0.4,\n",
        "                        use_normalized_coordinates=True,\n",
        "                        line_thickness=10)\n",
        "            \n",
        "\n",
        "            # Size, in inches, of the output images.\n",
        "            IMAGE_SIZE = (12, 8)\n",
        "            plt.figure(figsize=IMAGE_SIZE)\n",
        "            plt.imshow(image_np)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btn2HUebgKoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research\\\\object_detection\\\\150.jpg'\n",
        "run_inference_for_single_image(image, detection_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WgDw_zDgKol",
        "colab_type": "text"
      },
      "source": [
        "## 5. Object Detection on Video (Optional) \n",
        "\n",
        "The following codes will perform detection real-time on video. It reads the video frame one by one and and perform detection and draw the bounding boxes on each frame (image) and then display the image frame directly using cv2.imshow()\n",
        "\n",
        "Only run this when you are using a local computer, as the cv2 video player window is shown as a separate window on local computer, not within the notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyXfypDgKol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def run_inference_for_video(video_filepath, graph):\n",
        "    video_player = cv2.VideoCapture(video_filepath)\n",
        "\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
        "            detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
        "            detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
        "            detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "            while video_player.isOpened():\n",
        "                ret, image_np = video_player.read()\n",
        "                if ret:\n",
        "                    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "                    (boxes, scores, classes, num) = sess.run(\n",
        "                      [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "                      feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                        image_np,\n",
        "                        np.squeeze(boxes),\n",
        "                        np.squeeze(classes).astype(np.int32),\n",
        "                        np.squeeze(scores),\n",
        "                        category_index,\n",
        "                        use_normalized_coordinates=True,\n",
        "                        line_thickness=10)\n",
        "\n",
        "                    cv2.imshow('Object Detection', image_np)\n",
        "                    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "                        break\n",
        "                else:\n",
        "                    break\n",
        "                    \n",
        "    # Release camera and close windows\n",
        "    video_player.release()\n",
        "    cv2.destroyAllWindows() \n",
        "    cv2.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68Y7zVNSgKoo",
        "colab_type": "text"
      },
      "source": [
        "The following code is slightly modified to read the video file frame by frame and perform detection on the frame and write the detected frame to a video file usig VideoWriter class provided by openCV. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQu0elOsgKoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_video(video_in_filepath, video_out_filepath, graph):\n",
        "    if not os.path.exists(video_in_filepath):\n",
        "        print('video filepath not valid')\n",
        "    \n",
        "    video_reader = cv2.VideoCapture(video_in_filepath)\n",
        "    \n",
        "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "    video_writer = cv2.VideoWriter(video_out_filepath,\n",
        "                               cv2.VideoWriter_fourcc(*'XVID'), \n",
        "                               30.0, \n",
        "                               (frame_w, frame_h))\n",
        "\n",
        "    with graph.as_default():\n",
        "        with tf.compat.v1.Session() as sess:\n",
        "            image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
        "            detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
        "            detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
        "            detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "            for i in tqdm(range(nb_frames)):\n",
        "                ret, image_np = video_reader.read()\n",
        "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "                (boxes, scores, classes, num) = sess.run(\n",
        "                  [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "                  feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                    image_np,\n",
        "                    np.squeeze(boxes),\n",
        "                    np.squeeze(classes).astype(np.int32),\n",
        "                    np.squeeze(scores),\n",
        "                    category_index,\n",
        "                    use_normalized_coordinates=True,\n",
        "                    line_thickness=10)\n",
        "\n",
        "                video_writer.write(np.uint8(image_np))\n",
        "                \n",
        "    # Release camera and close windows\n",
        "    video_reader.release()\n",
        "    video_writer.release() \n",
        "    cv2.destroyAllWindows() \n",
        "    cv2.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBDmEe4GgKos",
        "colab_type": "text"
      },
      "source": [
        "Run this code to create a video file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3E2d1J1gKot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_in_file = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research\\\\object_detection\\\\pro.mp4'\n",
        "video_out_file = 'C:\\\\Users\\\\user\\\\Documents\\\\tensorflow\\\\models\\\\research\\\\object_detection\\\\pro_detect.mp4'\n",
        "\n",
        "write_video(video_in_file, video_out_file, detection_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7VBEr39gKox",
        "colab_type": "text"
      },
      "source": [
        "Run this code to detect and display realtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaEkSsedgKox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#video_in_file = 'data/tube.mp4'\n",
        "#run_inference_for_video(video_in_file, detection_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG_vqFDIgKo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}